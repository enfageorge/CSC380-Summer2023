{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04b8856d",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a497416a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e08b517",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Administrative\n",
    "\n",
    "\n",
    "- Homework0 is due this June 17 Saturday, 5 pm\n",
    "- Office Hours by appointment anytime till June 17, 3 pm.\n",
    "- Weekly Check-in is open. Answer based on Lecture 2 and 3.\n",
    "- There have been updates to syllabus. Check announcements on D2L.\n",
    "- Homework 0 will be released on Sunday, and you will have atleast 7 days to work on it. \n",
    "- Students who are thinking about having this course for honours credit, please setup an appointment with me asap."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fb6fdf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Last Lecture\n",
    "\n",
    "- Random Events\n",
    "- What is Probability?\n",
    "- Probability Axioms\n",
    "    - Lemma\n",
    "    - Operations\n",
    "- Random Variable\n",
    "- Probability Distribution:\n",
    "- Probability Mass Function and Probability Density Function.\n",
    "- Joint, Marginal and Conditional Probability\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407248e7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Probabilty Week 8 (July 23 - July 29 ) will discuss\n",
    "\n",
    "- Discrete Probability Distributions and Continuous Probability.\n",
    "- Some useful probability distributions\n",
    "\n",
    "Some probability distributions will be introduced when talking about examples throughout the course"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396bcaf8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## In this Lecture\n",
    "\n",
    "- Expectation of a Random Variable\n",
    "- Moments of Random Variable\n",
    "- Variance and Standard Deviation\n",
    "- Corelation\n",
    "- Covariance\n",
    "- Independence of Random Variable\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48419bd7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Expectation Random variable\n",
    "\n",
    "The expectation or expected value, is the weighted average<br>\n",
    "value of a random variable.\n",
    "\n",
    "#### Discrete Random variable\n",
    "\n",
    "\n",
    "|  |  |\n",
    "| ------------- | ------------- |\n",
    "| <img src = Https://www.rapidtables.com/math/probability/expectation/disc_expectation.gif> |<img src = https://d138zd1ktt9iqe.cloudfront.net/media/seo_landing_files/discrete-probability-distribution-graph-1639994506.png height = 300 width = 300> |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51aee8be",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Consider the probability that the random variable 𝑋 equals 1, when h = 1, and t = 0.\n",
    "\n",
    "There are two outcomes that lead to  𝑋 taking the value 1, namely  ℎ𝑡  and  𝑡ℎ. So, the probability that  𝑋=1 is given by the probability of the event  ℎ𝑡,𝑡ℎ , which is  0.5\n",
    " \n",
    " <centre> $$ 𝑝(1)= 𝑃(𝑋=1) = 𝑃 ( {ℎ𝑡,𝑡ℎ} ) =0.5  $$ </centre>\n",
    "    \n",
    "<centre>          $$𝑝(0) = 𝑃(𝑋=0) = 𝑃 ({𝑡𝑡}) = 0.25$$</centre>\n",
    "    \n",
    " <centre>   $$𝑝(2)=𝑃(𝑋=2)=𝑃 ({ℎℎ}) =0.25$$</centre>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b0ad9c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We are intrested in finding out the probability that  𝑋 takes a value in  𝐴={1,2}\n",
    "\n",
    " <sub> <centre> $$ 𝑝(1)= 𝑃(𝑋=1) = 𝑃 ( {ℎ𝑡,𝑡ℎ} ) =0.5  $$ </centre></sub>\n",
    "    \n",
    "<sub><centre>          $$𝑝(0) = 𝑃(𝑋=0) = 𝑃 ({𝑡𝑡}) = 0.25$$</centre></sub>\n",
    "    \n",
    " <sub><centre>   $$𝑝(2)=𝑃(𝑋=2)=𝑃 ({ℎℎ}) =0.25$$</centre></sub>\n",
    "\n",
    " <centre>$$ 𝑃(𝑋≥1)=𝑃(𝑋∈𝐴)=∑𝑥𝑖∈𝐴𝑝(𝑥𝑖)=𝑝(1)+𝑝(2)=0.5+0.25=0.75$$ </centre>\n",
    "\n",
    "<sub><sup>[Source - Example from LibreTexts](https://stats.libretexts.org/Courses/Saint_Mary's_College_Notre_Dame/DSCI_500B_Essential_Probability_Theory_for_Data_Science_(Kuter)/03%3A_Discrete_Random_Variables/3.02%3A_Probability_Mass_Functions_(PMFs)_and_Cumulative_Distribution_Functions_(CDFs)_for_Discrete_Random_Variables#Example_.5C(.5CPageIndex.7B2.7D.5C) </sub></sup> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70afe18f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src = \"images/44.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e20fb5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Continious Random variable\n",
    "\n",
    "\n",
    "|  |  |\n",
    "| ------------- | ------------- |\n",
    "| <img src = https://www.rapidtables.com/math/probability/expectation/cont_expectation.gif> | <img src = https://intellipaat.com/wp-content/uploads/2015/09/probability-for-a-continuous-random-variable.png>   |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db9c1a5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We defined the continuous random variable  𝑋\n",
    "  to denote the time a person waits for an elevator to arrive. The pdf of  𝑋\n",
    "  \n",
    " <img src = \"images/4.png\" height= 300 width = 300>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e96a03",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The expected value of  𝑋 :\n",
    "\n",
    "<img src= \"images/5.png\" >\n",
    "\n",
    "<sub><sup>[Source - Example from LibreTexts](https://stats.libretexts.org/Courses/Saint_Mary's_College_Notre_Dame/DSCI_500B_Essential_Probability_Theory_for_Data_Science_(Kuter)/03%3A_Discrete_Random_Variables/3.02%3A_Probability_Mass_Functions_(PMFs)_and_Cumulative_Distribution_Functions_(CDFs)_for_Discrete_Random_Variables#Example_.5C(.5CPageIndex.7B2.7D.5C) </sub></sup> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878c3872",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Expectation of $E[X]$ or ( Weighted )Average or Mean\n",
    "\n",
    "<img src = Https://www.rapidtables.com/math/probability/expectation/disc_expectation.gif width = 300 height = 300> for discrete random variables \n",
    "\n",
    "<img src = https://www.rapidtables.com/math/probability/expectation/cont_expectation.gif width = 300 height = 300> for continous random variables\n",
    "\n",
    "For uniform distribution, ie every outcomes has equal probability, this becomes a simple average we are familar with.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea6da6f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Note : The expected value could be something that is not even possible. For instance, for a fair six-sided die:\n",
    "\n",
    "\n",
    "<img src = \"images/7.png\" height = 500  width = 500>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc571bd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Theorem : Linearity of Expectations\n",
    "\n",
    "For any finite collection of discrete RVs with finite expectations,\n",
    "\n",
    "<img src = \"images/8.png\" height = 300  width = 300>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdecd405",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Example : Throw two fair six-sided dice. \n",
    "\n",
    "What is the expected sum? Let X and Y be the outcome of the first and second die,respectively.\n",
    "\n",
    "<img src = \"images/9.png\" height = 400  width = 400>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d234302c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What is the expectation of a constant c?\n",
    "\n",
    "<img src = \"images/10.png\" height = 100  width = 100>\n",
    "\n",
    "So, combined with the previous theorm we just saw,\n",
    "\n",
    "<img src = \"images/12.png\" height = 200  width = 200>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a2fd1c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let X and Y be the outcome of two fair six-sided dice, \n",
    "\n",
    "<img src=\"images/13.png\" width =300 height =300>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a585088",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conditional Expectation\n",
    "\n",
    "<img src=\"images/14.png\" width =600 height =600>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43657a4c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Example:  \n",
    "\n",
    "Roll two standard six-sided dice and let be the result of the first die and let be the sum of both dice, then:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b936c31c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "<img src=\"images/15.png\" width =600 height =600>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fd5130",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Law of Total Expectation\n",
    "\n",
    "<img src=\"images/14.png\" width =500 height =500>\n",
    "\n",
    "We can think of \n",
    "\n",
    "$$ E[X] = E[X|Y]. Pr(Y) +  E[X| \\overline{Y}] . Pr(\\overline{Y}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4402f37e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"images/16.png\" width =400. height = 400 >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145f0049",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What about the of the expectation of  $𝑋^2$?\n",
    "\n",
    "<img src = https://www.rapidtables.com/math/probability/expectation/cont_expectation.gif>\n",
    "\n",
    "<img src = \"images/6.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7243908",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "That actually, ie $E(X^2)$ is called the second moment of the random variable X\n",
    "\n",
    "$E(X^3)$ is the third moment, $E(X^4)$ is the fourth moment and so on.\n",
    "\n",
    "Moments characterize properties of the distribution “shape”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ef63f4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Moments of a Random Variable \n",
    "\n",
    "The “moments” of a random variable (or of its distribution) are expected values of powers or related functions of the random variable.\n",
    "\n",
    "<img src = \"images/17.png\" width = 300 height = 300>\n",
    "\n",
    "We call these non-central moments of order n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a8e1f0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Typically, \n",
    "\n",
    "<img src = \"images/18.png\" width = 300 height = 300>\n",
    "\n",
    "We call these central moments.\n",
    "\n",
    "We are now going to discuss a few central moments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247e1a37",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Variance\n",
    "\n",
    "The second central moment $(n=2)$\n",
    "\n",
    "So based on the previous slide, what would be the formula to compute variance?\n",
    "\n",
    "<img src = \"images/18.png\" width = 200 height = 200>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee5da6c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"images/19.png\" width = 400 height = 400>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c8f71d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Standard deviation\n",
    "\n",
    "Is the square root of variance.\n",
    "\n",
    "<img src = \"images/20.png\" width = 300 height = 300>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f659b23",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src = 'https://storage.googleapis.com/strictlybythenumbers_public/strictly_article/articles/image.png'>\n",
    "\n",
    "<sub><sup>[Source - Strictly By Numbers](https://www.strictlybythenumbers.com/bias-vs-variance)</sub></sup> \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a70278",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Let X be the result of a fair six-sided die, what is the variance and standard deviation of X?\n",
    "\n",
    "\n",
    "<img src = \"images/21.png\" width = 300 height = 300>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dd2313",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"images/22.png\" width = 600 height = 600>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874607ab",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"images/23.png\" width = 150 height = 150>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b313c6e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src = \"images/24.png\" width = 150 height = 150>\n",
    "\n",
    "$$ X = 3.5 \\pm 1.71 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033a7de6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lemma on Variance\n",
    "\n",
    "<img src= \"images/25.png\" width = 400 height = 400>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c7eb54",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src= \"images/38.png\" width = 400 height = 400>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89745988",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Covariance\n",
    "\n",
    "Suppose we have two variable X the temparature of the day , and Y your electric usage for the day. When temparature goes up, your electric usage is likely to go up. and vice versa.\n",
    "\n",
    "Covariance talks about the *linear* relationship between X and Y.\n",
    "\n",
    "Specifically it talks about how both X and Y differ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3858a2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<centre><img src= \"images/27.png\" width = 400 height = 400></centre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48ba497",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<centre> <img src= \"images/28.png\" width = 400 height = 400></centre> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7af348",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<centre><img src= \"images/29.png\" width = 400 height = 400></centre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94691ef",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The covariance of two Random Variables X and Y  is defined as,\n",
    "\n",
    "<img src= \"images/30.png\" width = 400 height = 400>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa19bbca",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What is $Cov(X,X)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a634d3a1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "It is simply $Var(X)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa8af3e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Covariance \n",
    "\n",
    "Lemma \n",
    "\n",
    "<img src= \"images/32.png\" width = 500 height = 500>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499331fa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Covariance shows you how the two variables differ, is there a way to know how the two variables are related?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc24ec4f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Corelation \n",
    "\n",
    "<img src= \"images/33.png\" width = 500 height = 500>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a95e73",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src = \"https://www.statlect.com/images/linear-correlation-coefficient.png\" width =600 hight = 600>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9d0dba",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "< Break>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56ad92a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Independent Random variables\n",
    "\n",
    "Two random variables and are independent if and only if\n",
    "\n",
    "<img src=\"images/34.png\" width = 300 height = 300>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddcd97a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Mutually Independent Random variables\n",
    "\n",
    "Random varibale $X_1, X_2, ... X_n$  are mutually independent if and only if\n",
    "\n",
    "<img src=\"images/35.png\" width = 500 height = 500>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecceb339",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Independence is symmetric : \n",
    "\n",
    "$X\\perp Y \\Longleftrightarrow Y\\perp X$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91673cfb",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Also, \n",
    "\n",
    "<img src=\"images/37.png\" width = 800 height = 800>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a64f1d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Example : \n",
    "\n",
    "Let $ X_1, X_2 \\in {1,2...6} $  be RVs representing the result of rolling two fair standard die. What is the mean of their product?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f60fa82",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We saw that,\n",
    "\n",
    "<img src=\"images/40.png\" width = 200 height =200>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1124e03",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"images/41.png\" width = 300 height = 300>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b885785f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conditionally Independent Random Variables\n",
    "\n",
    "Two random variables and are conditionally independent given if and only if,\n",
    "\n",
    "<img src=\"images/36.png\" width = 500 height = 500>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a950be0a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Also, \n",
    "\n",
    "<img src=\"images/39.png\" width = 300 height = 300>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c646b5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is the variance of sum of two random variables X and Y that are independent?\n",
    "\n",
    "We saw earlier that , \n",
    "\n",
    "<img src= \"images/32.png\" width = 500 height = 500>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b525d9b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For independent variables, $Cov(X,Y) = 0$,\n",
    "\n",
    "hence : \n",
    "\n",
    "<img src= \"images/42.png\" width = 300 height = 300>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d02863",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Heads up!\n",
    "\n",
    "Even though wehen  $X$ and $Y$ are independent random variables,their $Covariance$ is 0, the opposite is  **NOT**  true.\n",
    "\n",
    "\n",
    "<img src= \"images/43.png\" width = 300 height = 300>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb67bc94",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For instance, \n",
    "\n",
    "Example Let $X$ be any Random Variable and $Y = X^2$ then, $Cov(X,Y)=0$, but as we can see they are dependent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f055a8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For a majority of the lecture, we have been talking about **Discrete** Random Variables. For **Continuous** Random varibale, all you have to do is replace the $\\sum$ with $\\int$, as we saw in the intial discussion on Expectation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafbd2a5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Expectation of $E[X]$ or ( Weighted )Average or Mean\n",
    "\n",
    "<img src = Https://www.rapidtables.com/math/probability/expectation/disc_expectation.gif> for discrete random variables \n",
    "\n",
    "<img src = https://www.rapidtables.com/math/probability/expectation/cont_expectation.gif> for continous random variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf45a487",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## In this Lecture\n",
    "\n",
    "- Expectation of a Random Variable\n",
    "- Moments of Random Variable\n",
    "- Variance and Standard Deviation\n",
    "- Corelation\n",
    "- Covariance\n",
    "- Independence of Random Variable\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "rise": {
   "enable_chalkboard": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
